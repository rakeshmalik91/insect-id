{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bbbeea6-955f-4b8a-a750-9eb6ede3a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c5c27f8-ff8e-4f83-9b5e-5f1083bb68d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea7f9a4b-8845-4c1a-9950-ecee19d3dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mynnlib\n",
    "from mynnlib import *\n",
    "\n",
    "dataset_dir = \"insect-dataset/odonata\"\n",
    "\n",
    "early_regex = r\"^.*-(early)$\"\n",
    "unidentified_regex = r\"^.*-(spp|genera|genera-spp)$\"\n",
    "early_or_unidentified_regex = r\"^.*-(early|spp|genera|genera-spp)$\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b582d-51c3-47b1-9ee4-6d2f3e352242",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01996247-6d25-4ff1-a2bd-b338c5554a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f\"{dataset_dir}/data\"):\n",
    "    shutil.rmtree(f\"{dataset_dir}/data\")\n",
    "os.makedirs(f\"{dataset_dir}/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5de8eae6-192a-45a8-a427-91a4a6cc1f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge early and imago classes\n",
    "# merge unnamed classes suffixed \"-0\"\n",
    "\n",
    "src_dir = \"insect-dataset/src/indianodonata.org\"\n",
    "for class_dir in os.listdir(src_dir):\n",
    "    if not os.path.exists(f\"{dataset_dir}/data/{re.sub(r\"-(early|0)\", \"\", class_dir)}\"):\n",
    "        os.makedirs(f\"{dataset_dir}/data/{re.sub(r\"-(early|0)\", \"\", class_dir)}\")\n",
    "    if os.listdir(f\"{src_dir}/{class_dir}\"):\n",
    "        if re.match(r\"^.*-(early|0)$\", class_dir):\n",
    "            for file in os.listdir(f\"{src_dir}/{class_dir}\"):\n",
    "                shutil.copy2(f\"{src_dir}/{class_dir}/{file}\", f\"{dataset_dir}/data/{re.sub(r\"-(early|0)\", \"\", class_dir)}/{file}\")\n",
    "        else:\n",
    "            for file in os.listdir(f\"{src_dir}/{class_dir}\"):\n",
    "                shutil.copy2(f\"{src_dir}/{class_dir}/{file}\", f\"{dataset_dir}/data/{class_dir}/{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebc60e43-20a9-4e58-8bd0-b26ce527175f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def copy_data_from(sources, add_early=False):\n",
    "    class_cnt = 0\n",
    "    img_cnt = 0\n",
    "    for more_data_dir in sources:\n",
    "        for class_dir in os.listdir(f\"{dataset_dir}/data\"):\n",
    "            if os.path.exists(f\"{more_data_dir}/{class_dir}\"):\n",
    "                # print(f\"Copying data for {class_dir}...\")\n",
    "                class_cnt += 1\n",
    "                for file in os.listdir(f\"{more_data_dir}/{class_dir}\"):\n",
    "                    shutil.copy2(f\"{more_data_dir}/{class_dir}/{file}\", f\"{dataset_dir}/data/{class_dir}/{file}\")\n",
    "                    img_cnt += 1\n",
    "            if add_early and os.path.exists(f\"{more_data_dir}/{class_dir}-early\"):\n",
    "                # print(f\"Copying data for {class_dir}-early...\")\n",
    "                class_cnt += 1\n",
    "                os.makedirs(f\"{dataset_dir}/data/{class_dir}-early/{file}\")\n",
    "                for file in os.listdir(f\"{more_data_dir}/{class_dir}-early\"):\n",
    "                    shutil.copy2(f\"{more_data_dir}/{class_dir}-early/{file}\", f\"{dataset_dir}/data/{class_dir}-early/{file}\")\n",
    "                    img_cnt += 1\n",
    "    print(f\"{img_cnt} images added into {class_cnt} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b4505f4-9cb5-4cea-99c8-163926f61e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32463 images added into 354 classes\n"
     ]
    }
   ],
   "source": [
    "copy_data_from([\"insect-dataset/src/odonata.inaturalist.org\"], add_early=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eb8c9aa-28b8-4ba6-bfc5-8585ae693a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 unsupported files\n"
     ]
    }
   ],
   "source": [
    "remove_file_cnt = 0\n",
    "valid_file_regex = r\"^.*\\\\.(jpg|jpeg|png|ppm|bmp|pgm|tif|tiff|webp)$\"\n",
    "for class_dir in os.listdir(f\"{dataset_dir}/data\"):\n",
    "    for file in os.listdir(f\"{dataset_dir}/data/{class_dir}\"):\n",
    "        if not re.match(valid_file_regex, file):\n",
    "            # os.remove(f\"{dataset_dir}/data/{class_dir}/{file}\")\n",
    "            remove_file_cnt += 0\n",
    "print(f\"Removed {remove_file_cnt} unsupported files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b72f2d2a-2b52-438d-9dd2-059cd1564f50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aciagrion-azureum\n",
      "acrogomphus-mohani\n",
      "aeshna-donaldi\n",
      "agriocnemis-dabreui\n",
      "agrionoptera-dorothea\n",
      "anisogomphus-orites\n",
      "aristocypha-immaculata\n",
      "asiagomphus-personatus\n",
      "bayadera-kali\n",
      "bayadera-longicauda\n",
      "burmargiolestes-laidlawi\n",
      "caconeura-gomphoides\n",
      "caconeura-obscura\n",
      "calicnemia-mukherjeei\n",
      "calicnemia-pyrrhosoma\n",
      "cephalaeschna-klapperichi\n",
      "cephalaeschna-masoni\n",
      "chlorogomphus-schmidti\n",
      "chloropetalia-olympicus\n",
      "coeliccia-dorothea\n",
      "coeliccia-prakritiae\n",
      "coeliccia-rossi\n",
      "coeliccia-sarbottama\n",
      "coeliccia-vacca\n",
      "davidius-kumaonensis\n",
      "davidius-malloryi\n",
      "davidius-zallorensis\n",
      "drepanosticta-annandalei\n",
      "elattoneura-nihari\n",
      "enallagma-immsi\n",
      "epallage-fatime\n",
      "gynacantha-albistyla\n",
      "gynacantha-andamanae\n",
      "gynacantha-apicalis\n",
      "gynacantha-biharica\n",
      "gynacantha-odoneli\n",
      "gynacantha-pallampurica\n",
      "gynacantha-rammohani\n",
      "gynacantha-rotundata\n",
      "himalagrion-exclamatione\n",
      "ictinogomphus-atrox\n",
      "idionyx-galeata\n",
      "idionyx-imbricata\n",
      "idionyx-intricata\n",
      "idionyx-minima\n",
      "idionyx-nadganiensis\n",
      "idionyx-nilgiriensis\n",
      "idionyx-periyashola\n",
      "idionyx-rhinoceroides\n",
      "ischnura-null\n",
      "libellago-aurantiaca\n",
      "lyriothemis-cleis\n",
      "macromia-annaimalaiensis\n",
      "macromia-cupricincta\n",
      "macromia-flavovittata\n",
      "macromia-ida\n",
      "macromia-pallida\n",
      "macromia-whitei\n",
      "megalogomphus-bicornutus\n",
      "microgomphus-chelifer\n",
      "microgomphus-verticalis\n",
      "neallogaster-annandalei\n",
      "neallogaster-latifrons\n",
      "neallogaster-ornata\n",
      "neallogaster-schmidti\n",
      "nesoxenia-lineata\n",
      "neurothemis-ramburi\n",
      "nychogomphus-saundersii\n",
      "oligoaeschna-andamani\n",
      "onychargia-indica\n",
      "onychogomphus-cacharicus\n",
      "onychogomphus-grammicus\n",
      "onychogomphus-malabarensis\n",
      "onychogomphus-meghalayanus\n",
      "onychogomphus-thienemanni\n",
      "ophiogomphus-cerastis\n",
      "orthetrum-anceps\n",
      "orthetrum-cancellatum\n",
      "orthetrum-martensi\n",
      "orthetrum-testaceaum\n",
      "paragomphus-lindgreni\n",
      "periaeschna-lebasi\n",
      "periaeschna-magdalena\n",
      "periaeschna-nocturnalis\n",
      "petaliaeschna-fletcheri\n",
      "planaeschna-intersedens\n",
      "platycnemis-dealbata\n",
      "polycanthagyna-ornithocephala\n",
      "prodasineura-odoneli\n",
      "protosticta-rufostigma\n",
      "pseudagrion-andamanicum\n",
      "pseudagrion-bidentatum\n",
      "pseudagrion-pruinosum\n",
      "pseudocopera-superplatypes\n",
      "pseudotramea-prateri\n",
      "rhinocypha-ignipennis\n",
      "rhinocypha-immaculata\n",
      "rhinocypha-trimaculata\n",
      "rhinocypha-vitrinella\n",
      "rhyothemis-obsolescens\n",
      "sarasaeschna-martini\n",
      "sarasaeschna-speciosa\n",
      "schmidtiphaea-schmidi\n",
      "selysiothemis-nigra\n",
      "sympetrum-durum\n",
      "sympetrum-himalayanum\n",
      "sympetrum-hypomelas\n",
      "sympetrum-meridionale\n",
      "vestalis-submontana\n",
      "zygonyx-torrida\n",
      "\n",
      "Removed 110 empty classes\n"
     ]
    }
   ],
   "source": [
    "# list empty classes\n",
    "empty_class_cnt = 0\n",
    "for class_dir in os.listdir(f\"{dataset_dir}/data\"):\n",
    "    if not os.listdir(f\"{dataset_dir}/data/{class_dir}\"):\n",
    "        print(class_dir)\n",
    "        shutil.rmtree(f\"{dataset_dir}/data/{class_dir}\")\n",
    "        empty_class_cnt += 1\n",
    "print(f\"\\nRemoved {empty_class_cnt} empty classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3791b-672a-4336-bb86-060c0978318f",
   "metadata": {},
   "source": [
    "# Create val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b794f579-3cf7-4bb6-83df-c9554e295157",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f\"{dataset_dir}/val\"):\n",
    "    shutil.rmtree(f\"{dataset_dir}/val\")\n",
    "os.makedirs(f\"{dataset_dir}/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fe7aabf-b3c7-4eb1-b65e-5e830237bde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332 images moved from data to val\n"
     ]
    }
   ],
   "source": [
    "move_src = \"data\"\n",
    "move_dst = \"val\"\n",
    "val_data_ratio = 0.03\n",
    "val_data_cnt = 0\n",
    "for class_dir in os.listdir(f\"{dataset_dir}/{move_src}\"):\n",
    "    for file in os.listdir(f\"{dataset_dir}/{move_src}/{class_dir}\"):\n",
    "        if random.random() < val_data_ratio:\n",
    "            if not os.path.exists(f\"{dataset_dir}/{move_dst}/{class_dir}\"):\n",
    "                os.makedirs(f\"{dataset_dir}/{move_dst}/{class_dir}\")\n",
    "            shutil.move(f\"{dataset_dir}/{move_src}/{class_dir}/{file}\", f\"{dataset_dir}/{move_dst}/{class_dir}/\")\n",
    "            val_data_cnt += 1\n",
    "print(f\"{val_data_cnt} images moved from {move_src} to {move_dst}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787ce615-69fb-497f-8b62-e92556349e74",
   "metadata": {},
   "source": [
    "# Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bde603fd-6678-4858-b455-275e3a0d73a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Class count :    427 ( Unidentified:     27 / Early-stage:      0 / Identified-adult:    400 )\n",
      "Total  Data count :  44256 ( Unidentified:    302 / Early-stage:      0 / Identified-adult:  43954 )\n"
     ]
    }
   ],
   "source": [
    "classes = { class_dir: len([ img for img in os.listdir(f\"{dataset_dir}/data/{class_dir}\") ]) for class_dir in os.listdir(f\"{dataset_dir}/data\") }\n",
    "early_classes = { class_name: count for class_name, count in classes.items() if re.match(early_regex, class_name) }\n",
    "unidentified_classes = { class_name: count for class_name, count in classes.items() if re.match(unidentified_regex, class_name) }\n",
    "print(f\"Total Class count : {len(classes):6} ( Unidentified: {len(unidentified_classes):6} / Early-stage: {len(early_classes):6} / Identified-adult: {len(classes) - len(unidentified_classes) - len(early_classes):6} )\")\n",
    "print(f\"Total  Data count : {sum(classes.values()):6} ( Unidentified: {sum(unidentified_classes.values()):6} / Early-stage: {sum(early_classes.values()):6} / Identified-adult: {sum(classes.values()) - sum(unidentified_classes.values()) - sum(early_classes.values()):6} )\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ea0836b-2cb2-460d-a785-b0adc77c87f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    25 classes with <=2 images\n",
      "    56 classes with <=5 images\n"
     ]
    }
   ],
   "source": [
    "img2_class = []\n",
    "img5_class = []\n",
    "for class_dir in os.listdir(f\"{dataset_dir}/data\"):\n",
    "    if not re.match(early_or_unidentified_regex, class_dir):\n",
    "        img_cnt = sum([1 for file in os.listdir(f\"{dataset_dir}/data/{class_dir}\")])\n",
    "        img2_class += [class_dir] if img_cnt <= 2 else []\n",
    "        img5_class += [class_dir] if img_cnt <= 5 else []\n",
    "print(f\"{len(img2_class):6} classes with <=2 images\")\n",
    "print(f\"{len(img5_class):6} classes with <=5 images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76688ab7-e7ea-4ad7-a808-5af12866c57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genera count: 145\n"
     ]
    }
   ],
   "source": [
    "generas = set()\n",
    "for class_name in classes:\n",
    "    generas.add(class_name.split('-')[0])\n",
    "print(f\"Genera count: {len(generas)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c032cbe0-eda8-4e1f-884a-0f19eb992f74",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e023de3b-0cb6-4fd2-b6f9-766e24bad388",
   "metadata": {},
   "source": [
    "### Model A (resnet-152) ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69a308ab-1f2e-4b5d-a523-7e76c1e2c21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1:\n",
      "Epoch    1 /    5  | Train Loss: 2.5883 Acc: 0.4226  | Val Loss: 1.2730 Acc: 0.6659  | Elapsed time: 0:14:55.580652\n",
      "Epoch    2 /    5  | Train Loss: 0.9480 Acc: 0.7312  | Val Loss: 0.9276 Acc: 0.7320  | Elapsed time: 0:26:11.469817\n",
      "Epoch    3 /    5  | Train Loss: 0.5371 Acc: 0.8314  | Val Loss: 0.8259 Acc: 0.7800  | Elapsed time: 0:38:14.889094\n",
      "Phase 2:\n",
      "Epoch    1 /    5  | Train Loss: 1.5621 Acc: 0.5991  | Val Loss: 0.9821 Acc: 0.7200  | Elapsed time: 0:12:02.660414\n",
      "Epoch    2 /    5  | Train Loss: 1.2620 Acc: 0.6670  | Val Loss: 0.8866 Acc: 0.7523  | Elapsed time: 0:23:54.011407\n",
      "Epoch    3 /    5  | Train Loss: 1.1369 Acc: 0.6969  | Val Loss: 0.8554 Acc: 0.7590  | Elapsed time: 0:39:33.472592\n",
      "Phase 3:\n",
      "Epoch    1 /    5  | Train Loss: 1.1157 Acc: 0.7028  | Val Loss: 0.8933 Acc: 0.7530  | Elapsed time: 0:12:17.588497\n",
      "Epoch    2 /    5  | Train Loss: 0.9032 Acc: 0.7602  | Val Loss: 0.7417 Acc: 0.7875  | Elapsed time: 0:24:34.782030\n",
      "Epoch    3 /    5  | Train Loss: 0.8050 Acc: 0.7840  | Val Loss: 0.7360 Acc: 0.7883  | Elapsed time: 0:36:53.609623\n",
      "Phase 4:\n",
      "Epoch    1 /    5  | Train Loss: 0.8703 Acc: 0.7675  | Val Loss: 0.7175 Acc: 0.7965  | Elapsed time: 0:12:31.356947\n",
      "Epoch    2 /    5  | Train Loss: 0.8330 Acc: 0.7757  | Val Loss: 0.7154 Acc: 0.8033  | Elapsed time: 0:24:57.551820\n",
      "Epoch    3 /    5  | Train Loss: 0.8011 Acc: 0.7850  | Val Loss: 0.6982 Acc: 0.8086  | Elapsed time: 0:37:22.755118\n",
      "Epoch    4 /    5  | Train Loss: 0.7732 Acc: 0.7918  | Val Loss: 0.6888 Acc: 0.8101  | Elapsed time: 0:49:52.416615\n",
      "Epoch    5 /    5  | Train Loss: 0.7524 Acc: 0.7982  | Val Loss: 0.6777 Acc: 0.8138  | Elapsed time: 1:02:35.473577\n",
      "Phase 5:\n",
      "Epoch    1 /    5  | Train Loss: 0.7299 Acc: 0.8048  | Val Loss: 0.6793 Acc: 0.8146  | Elapsed time: 0:12:39.650637\n",
      "Epoch    2 /    5  | Train Loss: 0.7254 Acc: 0.8053  | Val Loss: 0.6719 Acc: 0.8146  | Elapsed time: 0:25:24.507729\n",
      "Epoch    3 /    5  | Train Loss: 0.7246 Acc: 0.8059  | Val Loss: 0.6789 Acc: 0.8161  | Elapsed time: 0:38:02.756508\n",
      "Epoch    4 /    5  | Train Loss: 0.7336 Acc: 0.8055  | Val Loss: 0.6798 Acc: 0.8153  | Elapsed time: 0:50:39.002473\n",
      "Phase 6:\n",
      "Epoch    1 /    5  | Train Loss: 0.7186 Acc: 0.8097  | Val Loss: 0.6715 Acc: 0.8176  | Elapsed time: 0:12:30.963915\n",
      "Epoch    2 /    5  | Train Loss: 0.7128 Acc: 0.8081  | Val Loss: 0.6797 Acc: 0.8108  | Elapsed time: 0:25:04.574105\n"
     ]
    }
   ],
   "source": [
    "training_params = [\n",
    "    { \"idx\": 1, \"robustness\": 0.2, \"break_at_val_acc_diff\": 0.05},\n",
    "    { \"idx\": 2, \"robustness\": 0.5, \"break_at_val_acc_diff\": 0.02},\n",
    "    { \"idx\": 3, \"robustness\": 1.0, \"break_at_val_acc_diff\": 0.01},\n",
    "    { \"idx\": 4, \"robustness\": 2.0, \"break_at_val_acc_diff\": -0.000001},\n",
    "    { \"idx\": 5, \"robustness\": 2.0, \"break_at_val_acc_diff\": -0.000001},\n",
    "    { \"idx\": 6, \"robustness\": 2.0, \"break_at_val_acc_diff\": -0.000001}\n",
    "]\n",
    "for param in training_params:\n",
    "    print(f\"Phase {param[\"idx\"]}:\")\n",
    "    if param[\"idx\"] == 1:\n",
    "        model_data = init_model_for_training(f'{dataset_dir}/data', f'{dataset_dir}/val', \n",
    "                                             batch_size=32, arch=\"resnet152\", image_size=224, robustness=param[\"robustness\"],\n",
    "                                             lr=1e-4, weight_decay=1e-4, silent=True)\n",
    "    else:\n",
    "        model_data = prepare_for_retraining(model_data, f'{dataset_dir}/data', f'{dataset_dir}/val', \n",
    "                                            batch_size=32, image_size=224, robustness=param[\"robustness\"], silent=True)\n",
    "    train(model_data, 5, f\"{dataset_dir}/checkpoint.odonata.ta.ep{param[\"idx\"]:02}###.pth\", \n",
    "          break_at_val_acc_diff=param[\"break_at_val_acc_diff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5dab5e8-68e0-4fe8-85e0-b0ed0eb5b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = torch.load(f\"{dataset_dir}/checkpoint.odonata.ta.ep060000.pth\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc692f-7d8b-4c63-87f3-8da7bcc1c0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05361cdf-6c62-4432-a013-474f80d60fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87464f8d-c733-41fe-a52a-efa8e048dea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
