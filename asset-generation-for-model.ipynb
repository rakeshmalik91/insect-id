{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8127028e-031e-4af7-abee-30e2bb952b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01e181a3-f731-4210-b411-c26e373993a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0841a9c0-1580-435d-9763-a6bad0d62870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"D:/Projects/insect-id\")\n",
    "\n",
    "import torch\n",
    "from executorch.exir import to_edge_transform_and_lower\n",
    "from executorch.backends.xnnpack.partition.xnnpack_partitioner import XnnpackPartitioner\n",
    "\n",
    "# import mynnlib\n",
    "# from mynnlib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecce4f13",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(torchvision.\u001b[34m__file__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\__init__.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\_meta_registrations.py:25\u001b[39m\n\u001b[32m     20\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;129;43m@register_meta\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mroi_align\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43mmeta_roi_align\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligned\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrois\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrois must have shape as Tensor[K, 5]\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\_meta_registrations.py:18\u001b[39m, in \u001b[36mregister_meta.<locals>.wrapper\u001b[39m\u001b[34m(fn)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(fn):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorchvision\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextension\u001b[49m._has_ops():\n\u001b[32m     19\u001b[39m         get_meta_lib().impl(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(torch.ops.torchvision, op_name), overload_name), fn)\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "print(torchvision.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c677f65a-1ed6-4835-8ede-353b3bf93796",
   "metadata": {},
   "source": [
    "# Generate .pt and classes json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d965e04-42c5-4905-9c12-7316412e2520",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"models\"\n",
    "models = {\n",
    "    \"moth\": \"insect-dataset/moth/checkpoint.moth.tg.ep060001.pth\",\n",
    "    \"butterfly\": \"insect-dataset/butterfly/checkpoint.butterfly.te.ep050000.pth\",\n",
    "    \"lepidoptera\": \"insect-dataset/lepidoptera/checkpoint.lepidoptera.te.ep060004.pth\",\n",
    "    \"lepidoptera.v2alpha\": \"insect-dataset/lepidoptera/checkpoint.inc.lepidoptera.ta.i01.e19.pth\",\n",
    "    \"odonata\": \"insect-dataset/odonata/checkpoint.odonata.tc.ep060002.pth\",\n",
    "    \"cicada\": \"insect-dataset/cicada/checkpoint.cicada.te.ep060000.pth\",\n",
    "    \"root-classifier\": \"insect-dataset/root-classifier/checkpoint.root-classifier.tj.ep060001.pth\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7e8d938-6261-4e8e-8a7c-5eb601df7056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insect-dataset/moth/checkpoint.moth.tg.ep060001.pth\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(model_path):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     model_data = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     model = model_data[\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      6\u001b[39m     device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1530\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1528\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1529\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1530\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1531\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1532\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1533\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1534\u001b[39m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1535\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1536\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[32m   1538\u001b[39m     f_name = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:2122\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   2120\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[32m   2121\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m2122\u001b[39m result = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2123\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2125\u001b[39m torch._utils._validate_loaded_sparse_tensors()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:2111\u001b[39m, in \u001b[36m_load.<locals>.UnpicklerWrapper.find_class\u001b[39m\u001b[34m(self, mod_name, name)\u001b[39m\n\u001b[32m   2109\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   2110\u001b[39m mod_name = load_module_mapping.get(mod_name, mod_name)\n\u001b[32m-> \u001b[39m\u001b[32m2111\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\__init__.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\_meta_registrations.py:25\u001b[39m\n\u001b[32m     20\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;129;43m@register_meta\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mroi_align\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43mmeta_roi_align\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligned\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrois\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrois must have shape as Tensor[K, 5]\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\_meta_registrations.py:18\u001b[39m, in \u001b[36mregister_meta.<locals>.wrapper\u001b[39m\u001b[34m(fn)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(fn):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorchvision\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextension\u001b[49m._has_ops():\n\u001b[32m     19\u001b[39m         get_meta_lib().impl(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(torch.ops.torchvision, op_name), overload_name), fn)\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "for model_name, model_path in models.items():\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"{model_path}\")\n",
    "        model_data = torch.load(model_path, weights_only=False)\n",
    "        model = model_data['model']\n",
    "        device = torch.device(\"cpu\")\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        # ----- for excutorch android (requires python <= 3.12)\n",
    "        example_input = torch.randn(1, 3, 224, 224)\n",
    "        exported_program = torch.export.export(model, (example_input,))\n",
    "        executorch_program = to_edge_transform_and_lower(exported_program, partitioner=[XnnpackPartitioner()]).to_executorch()\n",
    "        pte_model_path = f\"{output_dir}/m.checkpoint.{model_name}.pte\"\n",
    "        with open(pte_model_path, \"wb\") as f:\n",
    "            f.write(executorch_program.buffer)\n",
    "        print(f\" --> {pte_model_path}\")\n",
    "\n",
    "        # ----- for pytorch android\n",
    "        # scripted_model = torch.jit.script(model)\n",
    "        # scripted_model_path = f\"{output_dir}/m.checkpoint.{model_name}.pt\"\n",
    "        # scripted_model.save(scripted_model_path)\n",
    "        # print(f\" --> {scripted_model_path}\")\n",
    "\n",
    "        class_file_path = f\"{output_dir}/classes.{model_name}.json\"\n",
    "        with open(class_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump(model_data['class_names'], file, indent=4)\n",
    "        print(f\" --> {class_file_path}\")\n",
    "\n",
    "metadata = load_json(\"insect-id-app/metadata.json\")\n",
    "metadata['root-classifier']['classes'] = load_json(\"models/classes.root-classifier.json\")\n",
    "dump_json(\"insect-id-app/metadata.json\", metadata)\n",
    "os.remove(\"models/classes.root-classifier.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e19d664-42ab-4e0e-8f13-0a1e28321950",
   "metadata": {},
   "source": [
    "# Model stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4abd2f4e-b67b-4bab-b920-325e4fea4363",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"insect-dataset\"\n",
    "metadata_path = \"insect-id-app/metadata.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "047d1c64-3161-4bb5-943f-ece5344e05cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = load_json(metadata_path)\n",
    "for species_type in ['lepidoptera', 'moth', 'butterfly', 'odonata', 'cicada']:\n",
    "    data_dir = f\"insect-dataset/{species_type}/data\"\n",
    "    if os.path.exists(data_dir):\n",
    "        if not metadata[species_type]['stats']:\n",
    "            metadata[species_type]['stats'] = {}\n",
    "        stats = metadata[species_type]['stats']\n",
    "        stats['class_count'] = len(os.listdir(f\"{data_dir}\"))\n",
    "        stats['species_count'] = len([class_name for class_name in os.listdir(f\"{data_dir}\") if not re.match(r\"^.*-(early|genera|spp)$\", class_name)])\n",
    "        stats['spp_class_count'] = len([class_name for class_name in os.listdir(f\"{data_dir}\") if re.match(r\"^.*-(genera|spp)$\", class_name)])\n",
    "        stats['early_stage_class_count'] = len([class_name for class_name in os.listdir(f\"{data_dir}\") if re.match(r\"^.*-(early)$\", class_name)])\n",
    "        stats['data_count'] = sum([len(os.listdir(f\"{data_dir}/{class_name}\")) for class_name in os.listdir(f\"{data_dir}\")])\n",
    "dump_json(metadata_path, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71b8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model size calculation\n",
    "\n",
    "metadata = load_json(metadata_path)\n",
    "for model_name in ['root-classifier', 'lepidoptera.v2alpha', 'lepidoptera', 'moth', 'butterfly', 'odonata', 'cicada']:\n",
    "    metadata[model_name]['size'] = 0\n",
    "    for file in [f\"{output_dir}/m.checkpoint.{model_name}.pt\", f\"{output_dir}/images.{model_name}.zip\", \n",
    "                    f\"{output_dir}/classes.{model_name}.json\", f\"{output_dir}/class_details.{model_name}.json\"]:\n",
    "        if os.path.exists(file):\n",
    "            metadata[model_name]['size'] += os.path.getsize(file)\n",
    "        else:\n",
    "            # for lepidoptera.v2alpha\n",
    "            file = file.replace(model_name, model_name.split('.')[0])\n",
    "            if os.path.exists(file):\n",
    "                metadata[model_name]['size'] += os.path.getsize(file)\n",
    "dump_json(metadata_path, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fb64919-e1a5-4728-b8b2-8060f158654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_stats(species_type):\n",
    "    min_val_data_cnt = 2\n",
    "    metadata = load_json(metadata_path)\n",
    "    print(f\"\\n{species_type}\\n\" + ('-' * 30))\n",
    "\n",
    "    # make val dataset uniform\n",
    "    dataset_dir = f\"{base_dir}/{species_type}\"\n",
    "    for class_name in os.listdir(f\"{dataset_dir}/data\"):\n",
    "        if not os.path.exists(f\"{dataset_dir}/val/{class_name}\"):\n",
    "            os.makedirs(f\"{dataset_dir}/val/{class_name}\")\n",
    "        val_data_cnt = len(os.listdir(f\"{dataset_dir}/val/{class_name}\"))\n",
    "        data_to_add = max(0, min_val_data_cnt - val_data_cnt)\n",
    "        if data_to_add > 0:\n",
    "            files = os.listdir(f\"{dataset_dir}/data/{class_name}\")\n",
    "            random.shuffle(files)\n",
    "            for file in files[:data_to_add]:\n",
    "                shutil.copy2(f\"{dataset_dir}/data/{class_name}/{file}\", f\"{dataset_dir}/val/{class_name}/{file}\")\n",
    "\n",
    "    # get accuracy\n",
    "    model_data = torch.load(models[species_type], weights_only=False)\n",
    "    top1 = validate_prediction_in_dir_top_k(f\"{base_dir}/{species_type}/val\", model_data, 1)\n",
    "    print(f\"Top 1 Success: {top1['success']}/{top1['total']} -> {100*top1['success']/top1['total']:.2f}%\")\n",
    "    top3 = validate_prediction_in_dir_top_k(f\"{base_dir}/{species_type}/val\", model_data, 3)\n",
    "    print(f\"Top 3 Success: {top3['success']}/{top3['total']} -> {100*top3['success']/top3['total']:.2f}%\")\n",
    "\n",
    "    # save in json\n",
    "    if not metadata[species_type]['stats']:\n",
    "        metadata[species_type]['stats'] = {}\n",
    "    stats = metadata[species_type]['stats']\n",
    "    stats['accuracy'] = f\"{100*top1['success']/top1['total']:.2f}%\"\n",
    "    stats['accuracy_top3'] = f\"{100*top3['success']/top3['total']:.2f}%\"\n",
    "    dump_json(metadata_path, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f25670fd-d2f5-4508-804b-fcf99ae72230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lepidoptera\n",
      "------------------------------\n",
      "Top 1 Success: 10667/11107 -> 96.04%\n",
      "Top 3 Success: 11038/11107 -> 99.38%\n"
     ]
    }
   ],
   "source": [
    "dump_stats(\"lepidoptera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e56ee5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "moth\n",
      "------------------------------\n",
      "Top 1 Success: 5692/6541 -> 87.02%\n",
      "Top 3 Success: 6204/6541 -> 94.85%\n"
     ]
    }
   ],
   "source": [
    "dump_stats(\"moth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60643ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "butterfly\n",
      "------------------------------\n",
      "Top 1 Success: 3017/3467 -> 87.02%\n",
      "Top 3 Success: 3302/3467 -> 95.24%\n"
     ]
    }
   ],
   "source": [
    "dump_stats(\"butterfly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8f2061d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "odonata\n",
      "------------------------------\n",
      "Top 1 Success: 1416/1701 -> 83.25%\n",
      "Top 3 Success: 1589/1701 -> 93.42%\n"
     ]
    }
   ],
   "source": [
    "dump_stats(\"odonata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c350dd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cicada\n",
      "------------------------------\n",
      "Top 1 Success: 280/449 -> 62.36%\n",
      "Top 3 Success: 317/449 -> 70.60%\n"
     ]
    }
   ],
   "source": [
    "dump_stats(\"cicada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34068adf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
