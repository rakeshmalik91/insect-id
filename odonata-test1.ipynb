{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bbbeea6-955f-4b8a-a750-9eb6ede3a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c5c27f8-ff8e-4f83-9b5e-5f1083bb68d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea7f9a4b-8845-4c1a-9950-ecee19d3dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mynnlib\n",
    "from mynnlib import *\n",
    "\n",
    "dataset_dir = \"insect-dataset/odonata\"\n",
    "\n",
    "early_regex = r\"^.*-(early)$\"\n",
    "unidentified_regex = r\"^.*-(spp|genera|genera-spp)$\"\n",
    "early_or_unidentified_regex = r\"^.*-(early|spp|genera|genera-spp)$\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b582d-51c3-47b1-9ee4-6d2f3e352242",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01996247-6d25-4ff1-a2bd-b338c5554a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f\"{dataset_dir}/data\"):\n",
    "    shutil.rmtree(f\"{dataset_dir}/data\")\n",
    "os.makedirs(f\"{dataset_dir}/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5de8eae6-192a-45a8-a427-91a4a6cc1f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge early and imago classes\n",
    "src_dir = \"insect-dataset/src/indianodonata.org\"\n",
    "for class_dir in os.listdir(src_dir):\n",
    "    if not os.path.exists(f\"{dataset_dir}/data/{re.sub(r\"-early\", \"\", class_dir)}\"):\n",
    "        os.makedirs(f\"{dataset_dir}/data/{re.sub(r\"-early\", \"\", class_dir)}\")\n",
    "    if os.listdir(f\"{src_dir}/{class_dir}\"):\n",
    "        if class_dir.endswith(\"-early\"):\n",
    "            for file in os.listdir(f\"{src_dir}/{class_dir}\"):\n",
    "                shutil.copy2(f\"{src_dir}/{class_dir}/{file}\", f\"{dataset_dir}/data/{re.sub(r\"-early\", \"\", class_dir)}/{file}\")\n",
    "        else:\n",
    "            for file in os.listdir(f\"{src_dir}/{class_dir}\"):\n",
    "                shutil.copy2(f\"{src_dir}/{class_dir}/{file}\", f\"{dataset_dir}/data/{class_dir}/{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ebc60e43-20a9-4e58-8bd0-b26ce527175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data_from(sources, add_early=False):\n",
    "    class_cnt = 0\n",
    "    img_cnt = 0\n",
    "    for more_data_dir in sources:\n",
    "        for class_dir in os.listdir(f\"{dataset_dir}/data\"):\n",
    "            if os.path.exists(f\"{more_data_dir}/{class_dir}\"):\n",
    "                # print(f\"Copying data for {class_dir}...\")\n",
    "                class_cnt += 1\n",
    "                for file in os.listdir(f\"{more_data_dir}/{class_dir}\"):\n",
    "                    shutil.copy2(f\"{more_data_dir}/{class_dir}/{file}\", f\"{dataset_dir}/data/{class_dir}/{file}\")\n",
    "                    img_cnt += 1\n",
    "            if add_early and os.path.exists(f\"{more_data_dir}/{class_dir}-early\"):\n",
    "                # print(f\"Copying data for {class_dir}-early...\")\n",
    "                class_cnt += 1\n",
    "                os.makedirs(f\"{dataset_dir}/data/{class_dir}-early/{file}\")\n",
    "                for file in os.listdir(f\"{more_data_dir}/{class_dir}-early\"):\n",
    "                    shutil.copy2(f\"{more_data_dir}/{class_dir}-early/{file}\", f\"{dataset_dir}/data/{class_dir}-early/{file}\")\n",
    "                    img_cnt += 1\n",
    "    print(f\"{img_cnt} images added into {class_cnt} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b4505f4-9cb5-4cea-99c8-163926f61e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31089 images added into 332 classes\n"
     ]
    }
   ],
   "source": [
    "copy_data_from([\"insect-dataset/src/inaturalist.org\"], add_early=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ecd3a73-1cdd-4938-a3bb-231aedc4442b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 132 empty classes\n"
     ]
    }
   ],
   "source": [
    "removed_cnt = 0\n",
    "for class_dir in os.listdir(f\"{dataset_dir}/data\"):\n",
    "    if not os.listdir(f\"{dataset_dir}/data/{class_dir}\"):\n",
    "        shutil.rmtree(f\"{dataset_dir}/data/{class_dir}\")\n",
    "        removed_cnt += 1\n",
    "print(f\"Removed {removed_cnt} empty classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9eb8c9aa-28b8-4ba6-bfc5-8585ae693a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 unsupported files\n"
     ]
    }
   ],
   "source": [
    "remove_file_cnt = 0\n",
    "valid_file_regex = r\"^.*\\\\.(jpg|jpeg|png|ppm|bmp|pgm|tif|tiff|webp)$\"\n",
    "for class_dir in os.listdir(f\"{dataset_dir}/data\"):\n",
    "    for file in os.listdir(f\"{dataset_dir}/data/{class_dir}\"):\n",
    "        if not re.match(valid_file_regex, file):\n",
    "            # os.remove(f\"{dataset_dir}/data/{class_dir}/{file}\")\n",
    "            remove_file_cnt += 0\n",
    "print(f\"Removed {remove_file_cnt} unsupported files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3791b-672a-4336-bb86-060c0978318f",
   "metadata": {},
   "source": [
    "# Create val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b794f579-3cf7-4bb6-83df-c9554e295157",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f\"{dataset_dir}/val\"):\n",
    "    shutil.rmtree(f\"{dataset_dir}/val\")\n",
    "os.makedirs(f\"{dataset_dir}/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7fe7aabf-b3c7-4eb1-b65e-5e830237bde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1295 images moved from data to val\n"
     ]
    }
   ],
   "source": [
    "move_src = \"data\"\n",
    "move_dst = \"val\"\n",
    "val_data_ratio = 0.03\n",
    "val_data_cnt = 0\n",
    "for class_dir in os.listdir(f\"{dataset_dir}/{move_src}\"):\n",
    "    for file in os.listdir(f\"{dataset_dir}/{move_src}/{class_dir}\"):\n",
    "        if random.random() < val_data_ratio:\n",
    "            if not os.path.exists(f\"{dataset_dir}/{move_dst}/{class_dir}\"):\n",
    "                os.makedirs(f\"{dataset_dir}/{move_dst}/{class_dir}\")\n",
    "            shutil.move(f\"{dataset_dir}/{move_src}/{class_dir}/{file}\", f\"{dataset_dir}/{move_dst}/{class_dir}/\")\n",
    "            val_data_cnt += 1\n",
    "print(f\"{val_data_cnt} images moved from {move_src} to {move_dst}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787ce615-69fb-497f-8b62-e92556349e74",
   "metadata": {},
   "source": [
    "# Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bde603fd-6678-4858-b455-275e3a0d73a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Class count :    405 ( Unidentified:     27 / Early-stage:      0 / Identified-adult:    378 )\n",
      "Total  Data count :  42919 ( Unidentified:    296 / Early-stage:      0 / Identified-adult:  42623 )\n"
     ]
    }
   ],
   "source": [
    "classes = { class_dir: len([ img for img in os.listdir(f\"{dataset_dir}/data/{class_dir}\") ]) for class_dir in os.listdir(f\"{dataset_dir}/data\") }\n",
    "early_classes = { class_name: count for class_name, count in classes.items() if re.match(early_regex, class_name) }\n",
    "unidentified_classes = { class_name: count for class_name, count in classes.items() if re.match(unidentified_regex, class_name) }\n",
    "print(f\"Total Class count : {len(classes):6} ( Unidentified: {len(unidentified_classes):6} / Early-stage: {len(early_classes):6} / Identified-adult: {len(classes) - len(unidentified_classes) - len(early_classes):6} )\")\n",
    "print(f\"Total  Data count : {sum(classes.values()):6} ( Unidentified: {sum(unidentified_classes.values()):6} / Early-stage: {sum(early_classes.values()):6} / Identified-adult: {sum(classes.values()) - sum(unidentified_classes.values()) - sum(early_classes.values()):6} )\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ea0836b-2cb2-460d-a785-b0adc77c87f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    17 classes with <=2 images\n",
      "    48 classes with <=5 images\n"
     ]
    }
   ],
   "source": [
    "img2_class = []\n",
    "img5_class = []\n",
    "for class_dir in os.listdir(f\"{dataset_dir}/data\"):\n",
    "    if not re.match(early_or_unidentified_regex, class_dir):\n",
    "        img_cnt = sum([1 for file in os.listdir(f\"{dataset_dir}/data/{class_dir}\")])\n",
    "        img2_class += [class_dir] if img_cnt <= 2 else []\n",
    "        img5_class += [class_dir] if img_cnt <= 5 else []\n",
    "print(f\"{len(img2_class):6} classes with <=2 images\")\n",
    "print(f\"{len(img5_class):6} classes with <=5 images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "76688ab7-e7ea-4ad7-a808-5af12866c57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genera count: 143\n"
     ]
    }
   ],
   "source": [
    "generas = set()\n",
    "for class_name in classes:\n",
    "    generas.add(class_name.split('-')[0])\n",
    "print(f\"Genera count: {len(generas)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c032cbe0-eda8-4e1f-884a-0f19eb992f74",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e023de3b-0cb6-4fd2-b6f9-766e24bad388",
   "metadata": {},
   "source": [
    "### Model A (resnet-152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "69a308ab-1f2e-4b5d-a523-7e76c1e2c21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1:\n",
      "Epoch    1 /    5  | Train Loss: 2.5392 Acc: 0.4311  | Val Loss: 1.2621 Acc: 0.6672  | Elapsed time: 0:22:38.730906\n",
      "Epoch    2 /    5  | Train Loss: 0.9245 Acc: 0.7414  | Val Loss: 0.8889 Acc: 0.7367  | Elapsed time: 0:41:19.308152\n",
      "Epoch    3 /    5  | Train Loss: 0.5251 Acc: 0.8412  | Val Loss: 0.8412 Acc: 0.7591  | Elapsed time: 0:52:42.493943\n",
      "Phase 2:\n",
      "Epoch    1 /    5  | Train Loss: 1.5526 Acc: 0.6038  | Val Loss: 1.0386 Acc: 0.7174  | Elapsed time: 0:11:43.037567\n",
      "Epoch    2 /    5  | Train Loss: 1.2540 Acc: 0.6713  | Val Loss: 1.0289 Acc: 0.7042  | Elapsed time: 0:23:20.584905\n",
      "Phase 3:\n",
      "Epoch    1 /    5  | Train Loss: 1.1648 Acc: 0.6935  | Val Loss: 0.8529 Acc: 0.7529  | Elapsed time: 0:11:37.235206\n",
      "Epoch    2 /    5  | Train Loss: 1.0919 Acc: 0.7115  | Val Loss: 0.8612 Acc: 0.7598  | Elapsed time: 0:23:09.610912\n",
      "Phase 4:\n",
      "Epoch    1 /    5  | Train Loss: 0.9742 Acc: 0.7442  | Val Loss: 0.7642 Acc: 0.7838  | Elapsed time: 0:11:41.106220\n",
      "Epoch    2 /    5  | Train Loss: 0.8877 Acc: 0.7667  | Val Loss: 0.7238 Acc: 0.7961  | Elapsed time: 0:23:31.746927\n",
      "Epoch    3 /    5  | Train Loss: 0.8401 Acc: 0.7796  | Val Loss: 0.7276 Acc: 0.7946  | Elapsed time: 0:35:12.623989\n",
      "Phase 5:\n",
      "Epoch    1 /    5  | Train Loss: 0.8124 Acc: 0.7852  | Val Loss: 0.7071 Acc: 0.8093  | Elapsed time: 0:11:47.038650\n",
      "Epoch    2 /    5  | Train Loss: 0.7827 Acc: 0.7939  | Val Loss: 0.7077 Acc: 0.8093  | Elapsed time: 0:23:39.586948\n",
      "Epoch    3 /    5  | Train Loss: 0.7547 Acc: 0.8023  | Val Loss: 0.7079 Acc: 0.8116  | Elapsed time: 0:35:29.440521\n",
      "Epoch    4 /    5  | Train Loss: 0.7389 Acc: 0.8039  | Val Loss: 0.6890 Acc: 0.8069  | Elapsed time: 0:47:18.297894\n",
      "Phase 6:\n",
      "Epoch    1 /    5  | Train Loss: 0.7140 Acc: 0.8112  | Val Loss: 0.6704 Acc: 0.8124  | Elapsed time: 0:11:55.103301\n",
      "Epoch    2 /    5  | Train Loss: 0.7111 Acc: 0.8123  | Val Loss: 0.6983 Acc: 0.8046  | Elapsed time: 0:23:57.319562\n"
     ]
    }
   ],
   "source": [
    "training_params = [\n",
    "    { \"idx\": 1, \"robustness\": 0.2, \"break_at_val_acc_diff\": 0.05},\n",
    "    { \"idx\": 2, \"robustness\": 0.5, \"break_at_val_acc_diff\": 0.02},\n",
    "    { \"idx\": 3, \"robustness\": 1.0, \"break_at_val_acc_diff\": 0.01},\n",
    "    { \"idx\": 4, \"robustness\": 2.0, \"break_at_val_acc_diff\": -0.000001},\n",
    "    { \"idx\": 5, \"robustness\": 2.0, \"break_at_val_acc_diff\": -0.000001},\n",
    "    { \"idx\": 6, \"robustness\": 2.0, \"break_at_val_acc_diff\": -0.000001}\n",
    "]\n",
    "for param in training_params:\n",
    "    print(f\"Phase {param[\"idx\"]}:\")\n",
    "    if param[\"idx\"] == 1:\n",
    "        model_data = init_model_for_training(f'{dataset_dir}/data', f'{dataset_dir}/val', \n",
    "                                             batch_size=32, arch=\"resnet152\", image_size=224, robustness=param[\"robustness\"],\n",
    "                                             lr=1e-4, weight_decay=1e-4, silent=True)\n",
    "    else:\n",
    "        model_data = prepare_for_retraining(model_data, f'{dataset_dir}/data', f'{dataset_dir}/val', \n",
    "                                            batch_size=32, image_size=224, robustness=param[\"robustness\"], silent=True)\n",
    "    train(model_data, 5, f\"{dataset_dir}/checkpoint.odonata.ta.ep{param[\"idx\"]:02}###.pth\", \n",
    "          break_at_val_acc_diff=param[\"break_at_val_acc_diff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5dab5e8-68e0-4fe8-85e0-b0ed0eb5b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = torch.load(f\"{dataset_dir}/checkpoint.odonata.ta.ep060000.pth\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc692f-7d8b-4c63-87f3-8da7bcc1c0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05361cdf-6c62-4432-a013-474f80d60fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87464f8d-c733-41fe-a52a-efa8e048dea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
